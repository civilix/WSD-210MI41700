{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc571f14",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Prediction Insights\n",
    "**Analysis of CS2 Review Predictions**\n",
    "\n",
    "This notebook provides insights into the model's performance on the validation/test set.\n",
    "We verify the results using **Plotly** with the **Asimov (二西莫夫)** color scheme.\n",
    "\n",
    "**Focus:**\n",
    "1. Overall Performance (Confusion Matrix)\n",
    "2. Confidence Distribution (How sure is the model?)\n",
    "3. Error Analysis (Playtime, Review Length, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e474d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimov Color Scheme (二西莫夫配色)\n",
    "# High contrast, sci-fi/clean aesthetic.\n",
    "# Red (Negative), Blue/Cyan (Positive), Purple/Gold (Accents), Dark Background (Optional)\n",
    "\n",
    "ASIMOV_COLORS = ['#FF004D', '#00D4FF', '#FFD700', '#F2F2F2', '#1A1A2E']\n",
    "# Specific mapping for Binary Sentiment\n",
    "COLOR_MAP = {\n",
    "    0: '#FF004D',  # Negative (Neon Red)\n",
    "    1: '#00D4FF',  # Positive (Neon Cyan)\n",
    "    'Correct': '#00D4FF',\n",
    "    'Incorrect': '#FF004D'\n",
    "}\n",
    "\n",
    "def apply_asimov_layout(fig, title=\"\"):\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        title_x=0.5,\n",
    "        font=dict(family=\"Roboto, sans-serif\", size=14, color=\"#2c3e50\"),\n",
    "        plot_bgcolor=\"#f4f6f9\",\n",
    "        paper_bgcolor=\"#ffffff\",\n",
    "        margin=dict(l=40, r=40, t=80, b=40),\n",
    "        colorway=ASIMOV_COLORS\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Predictions\n",
    "try:\n",
    "    df = pd.read_csv(\"cs2_full_predictions.csv\")\n",
    "    print(f\"Loaded {len(df)} predictions.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'cs2_full_predictions.csv' not found. Please upload the results file.\")\n",
    "    # Create dummy data for demonstration if file is missing (Optional, handled by external dummy gen)\n",
    "    raise\n",
    "\n",
    "# Ensure types\n",
    "df['voted_up'] = df['voted_up'].astype(bool)\n",
    "df['predicted_label'] = df['predicted_label'].astype(int)\n",
    "\n",
    "# Add helper columns\n",
    "df['actual_label'] = df['voted_up'].map({False: 0, True: 1})\n",
    "df['result'] = np.where(df['actual_label'] == df['predicted_label'], 'Correct', 'Incorrect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84945c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(df['actual_label'], df['predicted_label'])\n",
    "z_text = [[str(y) for y in x] for x in cm]\n",
    "\n",
    "fig_cm = go.Figure(data=go.Heatmap(\n",
    "    z=cm,\n",
    "    x=['Predicted Negative', 'Predicted Positive'],\n",
    "    y=['Actual Negative', 'Actual Positive'],\n",
    "    text=z_text,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\": 20, \"color\": \"white\"},\n",
    "    colorscale=[[0, '#1A1A2E'], [1, '#00D4FF']], # Dark to Blue\n",
    "    showscale=True\n",
    "))\n",
    "\n",
    "apply_asimov_layout(fig_cm, \"Confusion Matrix\")\n",
    "fig_cm.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model Confidence Distribution\n",
    "# How confident is the model when it's right vs. wrong?\n",
    "\n",
    "fig_conf = px.histogram(\n",
    "    df, \n",
    "    x=\"predicted_prob\", \n",
    "    color=\"result\",\n",
    "    nbins=50,\n",
    "    color_discrete_map=COLOR_MAP,\n",
    "    opacity=0.7,\n",
    "    barmode=\"overlay\",\n",
    "    labels={\"predicted_prob\": \"Prediction Probability (Confidence)\", \"count\": \"Count\"}\n",
    ")\n",
    "\n",
    "apply_asimov_layout(fig_conf, \"Confidence Distribution: Correct vs Incorrect\")\n",
    "fig_conf.update_traces(marker_line_width=0)\n",
    "fig_conf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24465305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Playtime vs Accuracy\n",
    "# Does the model understand veterans (high playtime) better than new players?\n",
    "\n",
    "# Binning Playtime\n",
    "bins = [0, 10, 100, 1000, 100000]\n",
    "labels = ['<10h', '10-100h', '100-1000h', '>1000h']\n",
    "df['playtime_group'] = pd.cut(df['author.playtime_forever'] / 60, bins=bins, labels=labels) # Convert minutes to hours\n",
    "\n",
    "# Calculate accuracy per group\n",
    "acc_by_playtime = df.groupby('playtime_group')['result'].apply(lambda x: (x == 'Correct').mean()).reset_index()\n",
    "acc_by_playtime.columns = ['Playtime Group', 'Accuracy']\n",
    "\n",
    "fig_play = px.bar(\n",
    "    acc_by_playtime,\n",
    "    x='Playtime Group',\n",
    "    y='Accuracy',\n",
    "    color='Accuracy',\n",
    "    color_continuous_scale=['#FF004D', '#00D4FF'], # Red to Blue\n",
    "    text_auto='.2%'\n",
    ")\n",
    "\n",
    "apply_asimov_layout(fig_play, \"Model Accuracy by Player Experience (Playtime)\")\n",
    "fig_play.update_yaxes(range=[0, 1])\n",
    "fig_play.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c18de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Review Length vs Prediction Result\n",
    "# Are longer reviews harder to classify?\n",
    "\n",
    "df['review_length'] = df['review'].astype(str).apply(len)\n",
    "\n",
    "fig_len = px.box(\n",
    "    df,\n",
    "    x=\"result\",\n",
    "    y=\"review_length\",\n",
    "    color=\"result\",\n",
    "    color_discrete_map=COLOR_MAP,\n",
    "    points=\"outliers\"\n",
    ")\n",
    "\n",
    "apply_asimov_layout(fig_len, \"Review Length Distribution by Prediction Result\")\n",
    "fig_len.update_yaxes(type=\"log\", title=\"Review Length (Log Scale)\") # Log scale often helps with text length\n",
    "fig_len.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
